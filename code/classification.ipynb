{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -0- Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### A Possible way to deprecate warnings. We might not use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#--------------------------------#\n",
    "# To use later\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n",
    "# To use later\n",
    "#--------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -1- Data Preparing & Cleaning\n",
    "#### - We encode the labels/targets to 0, n-1.\n",
    "#### - Read the Excel\n",
    "#### - If testing some selected phases only, we drop the right columns and define our features\n",
    "#### - Data Cleaning with Aggelos' Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I50</th>\n",
       "      <th>Φ50</th>\n",
       "      <th>I150</th>\n",
       "      <th>Φ150</th>\n",
       "      <th>I250</th>\n",
       "      <th>Φ250</th>\n",
       "      <th>appliance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.619</td>\n",
       "      <td>2.6060</td>\n",
       "      <td>0.3099</td>\n",
       "      <td>-178.800</td>\n",
       "      <td>0.2033</td>\n",
       "      <td>5.325</td>\n",
       "      <td>PLAYR-TV+Tostiera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.572</td>\n",
       "      <td>0.6399</td>\n",
       "      <td>0.2669</td>\n",
       "      <td>-177.200</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>2.255</td>\n",
       "      <td>PLAYR-TV+Tostiera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.573</td>\n",
       "      <td>-179.0000</td>\n",
       "      <td>0.2675</td>\n",
       "      <td>2.851</td>\n",
       "      <td>0.2269</td>\n",
       "      <td>-174.200</td>\n",
       "      <td>PLAYR-TV+Tostiera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.573</td>\n",
       "      <td>0.8874</td>\n",
       "      <td>0.2661</td>\n",
       "      <td>-178.200</td>\n",
       "      <td>0.2292</td>\n",
       "      <td>2.440</td>\n",
       "      <td>PLAYR-TV+Tostiera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.572</td>\n",
       "      <td>0.9411</td>\n",
       "      <td>0.2664</td>\n",
       "      <td>-178.100</td>\n",
       "      <td>0.2284</td>\n",
       "      <td>3.350</td>\n",
       "      <td>PLAYR-TV+Tostiera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     I50       Φ50    I150     Φ150    I250     Φ250          appliance\n",
       "0  1.619    2.6060  0.3099 -178.800  0.2033    5.325  PLAYR-TV+Tostiera\n",
       "1  4.572    0.6399  0.2669 -177.200  0.2273    2.255  PLAYR-TV+Tostiera\n",
       "2  4.573 -179.0000  0.2675    2.851  0.2269 -174.200  PLAYR-TV+Tostiera\n",
       "3  4.573    0.8874  0.2661 -178.200  0.2292    2.440  PLAYR-TV+Tostiera\n",
       "4  4.572    0.9411  0.2664 -178.100  0.2284    3.350  PLAYR-TV+Tostiera"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Preparing\n",
    "# Encode labels with value 0-> n_classes -1\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Read excel with Pandas library\n",
    "path_to_dataset = \"../datasets/appliances_combination.xls\"\n",
    "#path_to_dataset= \"../datasets/one_appliance.xls\"\n",
    "\n",
    "# when you run it through azure notebooks\n",
    "#path_to_dataset= \"one_appliance.xls\"\n",
    "#path_to_dataset= \"appliances_combination.xls\"\n",
    "\n",
    "df = pd.read_excel(path_to_dataset)\n",
    "\n",
    "# Data Cleaning with Aggelos Rules for 50, 150, 250 phases\n",
    "df = df[(df.I50 > 0.1) & (df.I150 > 0.01) & (df.I250 > 0.01)]\n",
    "#print(df.shape)\n",
    "\n",
    "# These columns will be our features - X\n",
    "#features = ['I50', 'Φ50',]# 'I150', 'Φ150', 'I250', 'Φ250'] # # 50 Version\n",
    "#features = ['I150', 'Φ150',] # 150\n",
    "#features = ['I50', 'Φ50', 'I150', 'Φ150'] # 50-150\n",
    "#features = ['I250', 'Φ250'] #250\n",
    "#features = ['I50', 'Φ50', 'I150', 'Φ150',]# 'I250', 'Φ250'] # 50-150 Version\n",
    "features = ['I50', 'Φ50', 'I150', 'Φ150', 'I250', 'Φ250'] # 50-150-250 Version\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are going to test some selected phases, then you are going to remove some columns\n",
    "\n",
    "#df = df.drop(df.columns[cols],axis=1,inplace=True)\n",
    "#removeColumns = ['I150', 'Φ150', 'I250', 'Φ250'] # 50 \n",
    "#removeColumns = ['I50', 'Φ50', 'I250', 'Φ250'] # 150\n",
    "#removeColumns = ['I50', 'Φ50', 'I150', 'Φ150'] # 250\n",
    "#removeColumns = [ 'I250', 'Φ250'] # 50-150\n",
    "#columns = [ 'I250', 'Φ250'] \n",
    "#df.drop(removeColumns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -2- Data Scaling-Normalizing \n",
    "#### There is standard scaling, min-max scaling, robust scaling (preferred one) and normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.73248368 0.23790926 0.00890449 0.91041454 0.28352734 0.14491286]\n",
      " [0.41940973 0.18281675 0.04913007 0.90068722 0.10816284 0.09461722]\n",
      " [0.41979981 4.8509113  0.04856879 0.19394722 0.11108559 2.79623488]\n",
      " ...\n",
      " [0.10305838 0.38602939 0.15040756 1.20771107 1.40874006 0.54965345]\n",
      " [0.14635678 0.52579921 0.18324286 0.87819277 1.35759208 0.40777717]\n",
      " [0.23061312 0.47087763 0.14030439 0.85205058 1.41531622 0.42776436]]\n",
      "(array([    2,     2,    73, ..., 26482, 26482, 26499], dtype=int64), array([1, 5, 1, ..., 1, 5, 1], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# Features - X\n",
    "X = df[features]\n",
    "\n",
    "# Calculate Z-score in order to find outliers\n",
    "z = np.abs(stats.zscore(X))\n",
    "print(z) # Visualize\n",
    "threshold = 2.5 # Change the threshold arbitrarily\n",
    "print(np.where(z > threshold))\n",
    "df = df[(z < threshold).all(axis=1)] # Remove outliers that exceed the threshold given from dataset\n",
    "\n",
    "# Now get as X the 'clean' features\n",
    "X = df[features]\n",
    "\n",
    "# Scale the inputs (4 options; put comment in the ones you are not using)\n",
    "\n",
    "# -1- Standard Scaling\n",
    "#scaler = StandardScaler()\n",
    "#X = scaler.fit_transform(X)\n",
    "\n",
    "# -2- Min-max scaling \n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "#X = scaler.fit_transform(X)\n",
    "\n",
    "# -3- Robust scaling\n",
    "scaler = preprocessing.RobustScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# -4- Normalizing\n",
    "#scaler = preprocessing.Normalizer()\n",
    "#X = scaler.fit_transform(X)\n",
    "\n",
    "# Label - Y\n",
    "y = df['appliance']\n",
    "\n",
    "# Convert y to integer \n",
    "le.fit(y) # Fit label encoder\n",
    "y = le.transform(y) # Transform labels to normalized encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -3- Classifying (Method 1: Cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'f1_score' is not a valid scoring value. Valid options are ['accuracy', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'average_precision', 'completeness_score', 'explained_variance', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'fowlkes_mallows_score', 'homogeneity_score', 'mutual_info_score', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_median_absolute_error', 'normalized_mutual_info_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc', 'v_measure_score']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1683785636c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#clf = LogisticRegression()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-1683785636c7>\u001b[0m in \u001b[0;36mcross_val\u001b[1;34m(method, X, y, kfold_num)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcross_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkfold_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1_score'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \"\"\"\n\u001b[0;32m    334\u001b[0m     \u001b[1;31m# To ensure multimetric format is not supported\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    274\u001b[0m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;31m# Heuristic to ensure user has not passed a metric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[1;34m(scoring)\u001b[0m\n\u001b[0;32m    234\u001b[0m             raise ValueError('%r is not a valid scoring value. '\n\u001b[0;32m    235\u001b[0m                              \u001b[1;34m'Valid options are %s'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m                              % (scoring, sorted(scorers)))\n\u001b[0m\u001b[0;32m    237\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'f1_score' is not a valid scoring value. Valid options are ['accuracy', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'average_precision', 'completeness_score', 'explained_variance', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'fowlkes_mallows_score', 'homogeneity_score', 'mutual_info_score', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_median_absolute_error', 'normalized_mutual_info_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc', 'v_measure_score']"
     ]
    }
   ],
   "source": [
    "# a function that runs cross validation by giving as parameter the classification method\n",
    "# X,y, the score type (i.e 'accuracy', 'f1_score') and number of folds\n",
    "# Returns the score.\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\n",
    "def cross_val(method, X, y, kfold_num):\n",
    "    return cross_val_score(method, X, y, scoring='f1_score', cv=kfold_num)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state = 42)\n",
    "#clf = LogisticRegression()\n",
    "print(cross_val(clf, X, y, 10))\n",
    "\n",
    "clf = LogisticRegression()\n",
    "print(cross_val(clf, X, y, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -3- Classifying (Method 2: Train/Test Splitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "\n",
      "Accuracy: 0.431\n",
      "Precision: 0.365\n",
      "Recall: 0.431\n",
      "F1-Score: 0.356\n",
      "-----------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kasloujr\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\kasloujr\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Trees:\n",
      "\n",
      "Accuracy: 0.898\n",
      "Precision: 0.898\n",
      "Recall: 0.898\n",
      "F1-Score: 0.898\n",
      "-----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split to train & test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform Logistic Regression\n",
    "reg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "print(\"Logistic Regression:\")\n",
    "print(\"\\nAccuracy: %1.3f\" % reg.score(X_test, y_test))\n",
    "print(\"Precision: %1.3f\" % metrics.precision_score(y_test, y_pred, average ='weighted'))\n",
    "print(\"Recall: %1.3f\" % metrics.recall_score(y_test, y_pred, average ='weighted'))\n",
    "print(\"F1-Score: %1.3f\" % metrics.f1_score(y_test, y_pred, average ='weighted'))\n",
    "print(\"-----------------\\n\")\n",
    "\n",
    "# Decision Trees\n",
    "clf = DecisionTreeClassifier(random_state = 42) # Feel free to change 'min_samples_split' \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Decision Trees:\")\n",
    "print(\"\\nAccuracy: %1.3f\" % clf.score(X_test, y_test))\n",
    "print(\"Precision: %1.3f\" % metrics.precision_score(y_test, y_pred, average ='weighted'))\n",
    "print(\"Recall: %1.3f\" % metrics.recall_score(y_test, y_pred, average ='weighted'))\n",
    "print(\"F1-Score: %1.3f\" % metrics.f1_score(y_test, y_pred, average ='weighted'))\n",
    "print(\"-----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
