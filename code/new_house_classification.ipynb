{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparexy(df):\n",
    "    # Data Preparing\n",
    "    # Encode labels with value 0-> n_classes -1\n",
    "    \n",
    "    features = ['I50', 'Φ50', 'I150', 'Φ150', 'I250', 'Φ250']\n",
    "    \n",
    "    # Features - X\n",
    "    X = df[features]\n",
    "\n",
    "    # Calculate Z-score in order to find outliers\n",
    "    z = np.abs(stats.zscore(X))\n",
    "    #print(z) # Visualize\n",
    "    threshold = 2.5 # Change the threshold arbitrarily\n",
    "    #print(np.where(z > threshold))\n",
    "    df = df[(z < threshold).all(axis=1)] # Remove outliers that exceed the threshold given from dataset\n",
    "\n",
    "    # Now get as X the 'clean' features\n",
    "    X = df[features]\n",
    "\n",
    "    # Scale the inputs (4 options; put comment in the ones you are not using)\n",
    "\n",
    "    # -1- Standard Scaling\n",
    "    #scaler = StandardScaler()\n",
    "    #X = scaler.fit_transform(X)\n",
    "\n",
    "    # -2- Min-max scaling \n",
    "    #scaler = preprocessing.MinMaxScaler()\n",
    "    #X = scaler.fit_transform(X)\n",
    "\n",
    "    # -3- Robust scaling\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # -4- Normalizing\n",
    "    #scaler = preprocessing.Normalizer()\n",
    "    #X = scaler.fit_transform(X)\n",
    "\n",
    "    # Label - Y\n",
    "    y = df['appliance']\n",
    "\n",
    "    # Convert y to integer \n",
    "    le.fit(y) # Fit label encoder\n",
    "    y = le.transform(y) # Transform labels to normalized encoding\n",
    "    \n",
    "    return(X,y)\n",
    "\n",
    "def data_process(dataset_path):\n",
    "    df = pd.read_excel(dataset_path)\n",
    "\n",
    "    # Data Cleaning with Aggelos Rules for 50, 150, 250 phases\n",
    "    df = df[(df.I50 > 0.1) & (df.I150 > 0.01) & (df.I250 > 0.01)] # Clean useless current features\n",
    "\n",
    "\n",
    "    #df['Φ50'] = df['Φ50'].apply(pd.to_numeric)\n",
    "\n",
    "    # For angle between (90, 180):\n",
    "    # Modify by +180 degrees\n",
    "    rows_with_rads_to_decrease = df.loc[(df['Φ50'] > 90) & (df['Φ50'] < 180)]\n",
    "    rows_with_rads_to_decrease['Φ50'] -= 180\n",
    "    df.update(rows_with_rads_to_decrease)\n",
    "\n",
    "    # For angle between (-180, -90):\n",
    "    # Modify by -180 degrees\n",
    "    rows_with_rads_to_increase = (df.loc[(df['Φ50'] < -90) & (df['Φ50'] > -180)])\n",
    "    rows_with_rads_to_increase['Φ50'] += 180\n",
    "    df.update(rows_with_rads_to_increase)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets \n",
    "Split them if you have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaslou\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\kaslou\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the following if you want to train on house1 and test on house2:\n",
    "#X_train, y_train = preparexy(data_process(\"../datasets/appliances_combination_daskio.xls\"))\n",
    "#X_test, y_test = preparexy(data_process(\"../datasets/appliances_combination_veroia.xls\"))\n",
    "\n",
    "X, y = preparexy(data_process(\"../datasets/appliances_combination_daskio.xls\"))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## printMetrics method (Used when splitting train/test so you have a $X_{test}$ and a $y_{test}$)\n",
    "Takes as input the $classifier$, the $X_{test}$ and the $y_{test}$.\n",
    "\n",
    "Then it prints a detailed report with all the known metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMetrics(clf, X_test, y_test):\n",
    "    # Uncomment if you want confusion matrix to be shown\n",
    "    #cm = confusion_matrix(y_test, y_pred) \n",
    "    #print(\"Confusion matrix\")\n",
    "    #print(cm)\n",
    "    \n",
    "    \n",
    "    # This will print precision, recall, f1-score, support for all the categories\n",
    "    #target_names = ['class 0', 'class 1', 'class 2']\n",
    "    print(\"Classification report for classifier \\n%s:\\n%s\" % (clf, metrics.classification_report(y_test, y_pred)))\n",
    "    print(\"Accuracy: %1.3f\" % clf.score(X_test, y_test))\n",
    "    print(\"-----------------\\n\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Trees:\n",
      "Classification report for classifier \n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best'):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.97      0.98       118\n",
      "          1       0.85      0.81      0.83       144\n",
      "          2       0.94      0.92      0.93       132\n",
      "          3       0.82      0.83      0.82       130\n",
      "          4       0.91      0.94      0.93        53\n",
      "          5       0.97      0.92      0.95        93\n",
      "          6       0.93      0.94      0.93        96\n",
      "          7       0.98      0.96      0.97       141\n",
      "          8       0.76      0.76      0.76        51\n",
      "          9       0.92      0.91      0.91        86\n",
      "         10       1.00      1.00      1.00        39\n",
      "         11       0.95      0.91      0.93        46\n",
      "         12       0.93      1.00      0.96        40\n",
      "         13       0.89      0.97      0.93        33\n",
      "         14       0.98      0.94      0.96        52\n",
      "         15       0.96      0.96      0.96        28\n",
      "         16       0.97      0.94      0.96        36\n",
      "         17       0.82      1.00      0.90        14\n",
      "         18       0.86      0.79      0.83        24\n",
      "         19       0.90      0.90      0.90       334\n",
      "         20       0.87      0.86      0.86       228\n",
      "         21       0.93      0.96      0.95       284\n",
      "         22       0.90      0.88      0.89       301\n",
      "         23       0.86      0.85      0.85       126\n",
      "         24       0.97      0.94      0.95        97\n",
      "         25       0.88      0.84      0.86       193\n",
      "         26       0.88      0.91      0.89       280\n",
      "         27       0.89      0.92      0.90       186\n",
      "         28       0.89      0.86      0.87       197\n",
      "         29       0.92      0.90      0.91       116\n",
      "         30       0.91      0.92      0.91       156\n",
      "         31       0.93      0.95      0.94       175\n",
      "         32       0.81      0.85      0.83       157\n",
      "         33       0.91      0.89      0.90       157\n",
      "         34       0.85      0.94      0.89        47\n",
      "         35       0.93      0.90      0.92        78\n",
      "         36       0.86      0.88      0.87        57\n",
      "\n",
      "avg / total       0.90      0.90      0.90      4525\n",
      "\n",
      "Accuracy: 0.901\n",
      "-----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Trees\n",
    "clf = DecisionTreeClassifier(random_state = 42) # Feel free to change 'min_samples_split' \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Decision Trees:\")\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "printMetrics(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron with 18 neurons in 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4525, 6) (4525,)\n",
      "DVD-TV+Pistolaki+Mati\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaslou\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(le.inverse_transform(y_test[1])) # Check one TRUE class \n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(18,), random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Multi-layer Perceptron:\")\n",
    "y_pred = clf.predict(X_test)\n",
    "print(le.inverse_transform(y_pred[1])) # check one PREDICTED class\n",
    "\n",
    "#printMetrics(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
