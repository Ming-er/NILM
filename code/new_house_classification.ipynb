{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/klajdi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/klajdi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def preparexy(df):\n",
    "    # Data Preparing\n",
    "    # Encode labels with value 0-> n_classes -1\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    features = ['I50', 'Φ50', 'I150', 'Φ150', 'I250', 'Φ250']\n",
    "    \n",
    "    # Features - X\n",
    "    X = df[features]\n",
    "\n",
    "    # Calculate Z-score in order to find outliers\n",
    "    z = np.abs(stats.zscore(X))\n",
    "    #print(z) # Visualize\n",
    "    threshold = 2.5 # Change the threshold arbitrarily\n",
    "    #print(np.where(z > threshold))\n",
    "    df = df[(z < threshold).all(axis=1)] # Remove outliers that exceed the threshold given from dataset\n",
    "\n",
    "    # Now get as X the 'clean' features\n",
    "    X = df[features]\n",
    "\n",
    "    # Scale the inputs (4 options; put comment in the ones you are not using)\n",
    "\n",
    "    # -1- Standard Scaling\n",
    "    #scaler = StandardScaler()\n",
    "    #X = scaler.fit_transform(X)\n",
    "\n",
    "    # -2- Min-max scaling \n",
    "    #scaler = preprocessing.MinMaxScaler()\n",
    "    #X = scaler.fit_transform(X)\n",
    "\n",
    "    # -3- Robust scaling\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # -4- Normalizing\n",
    "    #scaler = preprocessing.Normalizer()\n",
    "    #X = scaler.fit_transform(X)\n",
    "\n",
    "    # Label - Y\n",
    "    y = df['appliance']\n",
    "\n",
    "    # Convert y to integer \n",
    "    le.fit(y) # Fit label encoder\n",
    "    y = le.transform(y) # Transform labels to normalized encoding\n",
    "    \n",
    "    return(X,y)\n",
    "\n",
    "def data_process(dataset_path):\n",
    "    df = pd.read_excel(dataset_path)\n",
    "\n",
    "    # Data Cleaning with Aggelos Rules for 50, 150, 250 phases\n",
    "    df = df[(df.I50 > 0.1) & (df.I150 > 0.01) & (df.I250 > 0.01)] # Clean useless current features\n",
    "\n",
    "\n",
    "    #df['Φ50'] = df['Φ50'].apply(pd.to_numeric)\n",
    "\n",
    "    # For angle between (90, 180):\n",
    "    # Modify by +180 degrees\n",
    "    rows_with_rads_to_decrease = df.loc[(df['Φ50'] > 90) & (df['Φ50'] < 180)]\n",
    "    rows_with_rads_to_decrease['Φ50'] -= 180\n",
    "    df.update(rows_with_rads_to_decrease)\n",
    "\n",
    "    # For angle between (-180, -90):\n",
    "    # Modify by -180 degrees\n",
    "    rows_with_rads_to_increase = (df.loc[(df['Φ50'] < -90) & (df['Φ50'] > -180)])\n",
    "    rows_with_rads_to_increase['Φ50'] += 180\n",
    "    df.update(rows_with_rads_to_increase)\n",
    "    \n",
    "    return df\n",
    "\n",
    "X_train, y_train = preparexy(data_process(\"../datasets/appliances_combination_daskio.xls\"))\n",
    "X_test, y_test = preparexy(data_process(\"../datasets/appliances_combination_veroia.xls\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2521719250114312"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Trees\n",
    "clf = DecisionTreeClassifier(random_state = 42) # Feel free to change 'min_samples_split' \n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
